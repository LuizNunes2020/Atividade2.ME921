import re
import requests
import csv
from bs4 import BeautifulSoup

# Definir os headers para a requisição
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}

class Vlr:
    def get_parse(self, url):
        """
        Faz uma requisição ao URL e retorna um objeto BeautifulSoup e o status code
        :param url: A URL da página que você quer parsear
        :return: Um objeto BeautifulSoup e o status code
        """
        resp = requests.get(url, headers=headers)
        html, status_code = resp.text, resp.status_code
        return BeautifulSoup(html, 'html.parser'), status_code

    def vlr_stats(self, url):
        html, status = self.get_parse(url)
        result = []
        for item in html.select("tbody tr"):
            player_data = item.text.strip().replace("\t", "").split("\n")
            player_name = player_data[0].strip()

            # get org name abbreviation via player variable
            try:
                org = player_data[1].strip()
            except IndexError:
                org = "N/A"

            # get all td items from mod-color-sq class
            color_sq = [stat.text.strip() for stat in item.select("td.mod-color-sq")]
            rat = color_sq[0] if len(color_sq) > 0 else "N/A"
            acs = color_sq[1] if len(color_sq) > 1 else "N/A"
            kd = color_sq[2] if len(color_sq) > 2 else "N/A"
            kast = color_sq[3] if len(color_sq) > 3 else "N/A"
            adr = color_sq[4] if len(color_sq) > 4 else "N/A"
            kpr = color_sq[5] if len(color_sq) > 5 else "N/A"
            apr = color_sq[6] if len(color_sq) > 6 else "N/A"
            fkpr = color_sq[7] if len(color_sq) > 7 else "N/A"
            fdpr = color_sq[8] if len(color_sq) > 8 else "N/A"
            hs = color_sq[9] if len(color_sq) > 9 else "N/A"
            cl = color_sq[10] if len(color_sq) > 10 else "N/A"

            result.append(
                {
                    "player": player_name,
                    "org": org,
                    "rating": rat,
                    "average_combat_score": acs,
                    "kill_deaths": kd,
                    "kill_assists_survived_traded": kast,
                    "average_damage_per_round": adr,
                    "kills_per_round": kpr,
                    "assists_per_round": apr,
                    "first_kills_per_round": fkpr,
                    "first_deaths_per_round": fdpr,
                    "headshot_percentage": hs,
                    "clutch_success_percentage": cl,
                }
            )

        return result

    def save_to_csv(self, data, filename):
        """
        Salva os dados em um arquivo CSV
        :param data: Lista de dicionários contendo os dados
        :param filename: Nome do arquivo CSV a ser salvo
        """
        keys = data[0].keys()
        with open(filename, 'w', newline='', encoding='utf-8') as output_file:
            dict_writer = csv.DictWriter(output_file, fieldnames=keys)
            dict_writer.writeheader()
            dict_writer.writerows(data)

if __name__ == "__main__":
    url = "https://www.vlr.gg/stats/?event_group_id=all&event_id=all&region=all&min_rounds=200&min_rating=1550&agent=all&map_id=all&timespan=all"
    vlr = Vlr()
    data = vlr.vlr_stats(url)
    vlr.save_to_csv(data, 'vlr_stats_5.csv')
